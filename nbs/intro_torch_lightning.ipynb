{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0a6923-1f9b-4c18-aeec-18b23f1a9057",
   "metadata": {},
   "source": [
    "# **GOAL**\n",
    "> This notebook is about basics flow of training neural nets in PyTorch and PyTorch-Lightning. Since PyTorch-Lighting is higher layer API of PyTorch (subclasses of nn.Module), so we won't have to code that much like PyTorch. This is very much similar to fastai, we'll see if it's any better (though I doubt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd288ce-b574-4c6f-98d9-43592b11d8e3",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "> We'll have a try with MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4fd0cd-583c-44e0-a607-57e79b611a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import ignite.metrics \n",
    "from ignite.metrics import Accuracy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69de4915-67d3-45ff-b2aa-1e6b18f7368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.9.0', 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check torch version & gpu:\n",
    "torch.__version__, torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeacd905-b68c-4e4f-866c-0f847751adc3",
   "metadata": {},
   "source": [
    "## Create datasets\n",
    "> Let's create our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f0779e-320c-4db1-9206-3007c5928840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddpham/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-19kunu9c/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download and create dataset from MNIST\n",
    "mnist_ds = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Split train, valid randomly:\n",
    "train_ds, valid_ds = random_split(mnist_ds, lengths=[55000, 5000])\n",
    "\n",
    "# Create dataloader with batch_size:\n",
    "batch_size = 64\n",
    "train_ds = DataLoader(train_ds, batch_size)\n",
    "valid_ds = DataLoader(valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd1021-6d32-47ec-afad-d43296605ffe",
   "metadata": {},
   "source": [
    "### Visualize images\n",
    "> It's always fun to visualize the dataset as much as we can, we know what we're dealing with, even though it's the well known MNIST! 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b2fed9-d052-4c60-9390-2dbb0bc8d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(ds):\n",
    "    for _, batch in enumerate(ds):\n",
    "        X, y = batch\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            # plt.imshow(X[i].numpy().reshape(28, 28, 1))\n",
    "            plt.imshow(np.repeat(X[i].numpy().reshape(28, 28, 1), 3, -1)) # return to 3 channels images\n",
    "            plt.title(y[i].numpy())\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf249ae-6e40-495a-8897-9f9e7918facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_images(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a374a-7672-4a58-8046-1fabad8dfb48",
   "metadata": {},
   "source": [
    "## Torch stuff\n",
    "> We're going to create a simple neural nets with `torch.nn` and create a training loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7becd-e7ca-4ac9-95ca-6bebc715487f",
   "metadata": {},
   "source": [
    "### Create simple neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9c74c0df-01b8-465f-850e-da0b21d26f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  simple sequential nn:\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    ")\n",
    "# Move model to cuda:\n",
    "model.cuda()\n",
    "\n",
    "parameters = model.parameters()\n",
    "# Create loss fuction:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create optimizer, keep default stuff:\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(parameters, lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f40ef6-9f0d-4999-b7d0-3a33cd4ad696",
   "metadata": {},
   "source": [
    "### Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "95a0c31e-1b2a-4005-bead-741e0c16b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  train_loss:  0.08,    train_accuracy:  0.97,    valid_loss:  0.12,    valid_accuracy:  0.96\n",
      "Epoch 2:  train_loss:  0.07,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 3:  train_loss:  0.06,    train_accuracy:  0.98,    valid_loss:  0.11,    valid_accuracy:  0.97\n",
      "Epoch 4:  train_loss:  0.05,    train_accuracy:  0.99,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 5:  train_loss:  0.04,    train_accuracy:  0.99,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 6:  train_loss:  0.03,    train_accuracy:  0.99,    valid_loss:  0.13,    valid_accuracy:  0.97\n",
      "Epoch 7:  train_loss:  0.03,    train_accuracy:  0.99,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 8:  train_loss:  0.02,    train_accuracy:  0.99,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 9:  train_loss:  0.02,    train_accuracy:  0.99,    valid_loss:  0.13,    valid_accuracy:  0.97\n",
      "Epoch 10:  train_loss:  0.02,    train_accuracy:  0.99,    valid_loss:  0.13,    valid_accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "# Create a training, validatign loops:\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Create train & valid losses & accuracies:\n",
    "    train_loss = list()\n",
    "    valid_loss = list()\n",
    "    train_accuracy = list()\n",
    "    valid_accuracy = list()\n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in train_ds:\n",
    "        x, y = batch\n",
    "        \n",
    "        # Convert X to batch_size x 1 x 28 x 28:\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda() # move x upto cuda so all steps calcuation related to x will be on cuda.\n",
    "        \n",
    "        # Step 1: forward step:\n",
    "        f = model(x)\n",
    "        \n",
    "        # Step 2: Compute loss value:\n",
    "        l = loss(f, y.cuda())\n",
    "        \n",
    "        # Step 3a: zero_grad (make all gradients to zero before accumulate them via nn):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Step 3b: accumulate gradients via all nns \n",
    "        l.backward()\n",
    "        \n",
    "        # Step 4: make updates (step) of the params based on gradients:\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append to loss and accuracies:\n",
    "        train_loss.append(l.item())\n",
    "        train_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in valid_ds:\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda()\n",
    "        with torch.no_grad(): f = model(x)\n",
    "        l = loss(f, y.cuda())\n",
    "        \n",
    "        # Append to loss and accuracies:\n",
    "        valid_loss.append(l.item())\n",
    "        valid_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "        \n",
    "    # After done with epoch, print loss of valid and train:\n",
    "    print(f'Epoch {epoch + 1}:  train_loss: {torch.tensor(train_loss).mean(): .2f},\\\n",
    "    train_accuracy: {torch.tensor(train_accuracy).mean(): .2f},\\\n",
    "    valid_loss: {torch.tensor(valid_loss).mean(): .2f},\\\n",
    "    valid_accuracy: {torch.tensor(valid_accuracy).mean(): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408b44e-6218-410b-9adb-6480ad4022af",
   "metadata": {},
   "source": [
    "### Update model with dropout\n",
    "> add dropout to reduce overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "65985336-167e-4a14-9752-d8c470d90888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  simple sequential nn:\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    "    nn.Linear(64, 10),\n",
    ")\n",
    "# Move model to cuda:\n",
    "model.cuda()\n",
    "\n",
    "parameters = model.parameters()\n",
    "# Create loss fuction:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create optimizer, keep default stuff:\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(parameters, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b04daab1-a011-45c7-9d3c-d36b5c50bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  train_loss:  0.45,    train_accuracy:  0.87,    valid_loss:  0.25,    valid_accuracy:  0.93\n",
      "Epoch 2:  train_loss:  0.20,    train_accuracy:  0.94,    valid_loss:  0.19,    valid_accuracy:  0.95\n",
      "Epoch 3:  train_loss:  0.15,    train_accuracy:  0.95,    valid_loss:  0.17,    valid_accuracy:  0.95\n",
      "Epoch 4:  train_loss:  0.12,    train_accuracy:  0.96,    valid_loss:  0.15,    valid_accuracy:  0.95\n",
      "Epoch 5:  train_loss:  0.10,    train_accuracy:  0.97,    valid_loss:  0.13,    valid_accuracy:  0.96\n",
      "Epoch 6:  train_loss:  0.08,    train_accuracy:  0.97,    valid_loss:  0.14,    valid_accuracy:  0.96\n",
      "Epoch 7:  train_loss:  0.07,    train_accuracy:  0.98,    valid_loss:  0.13,    valid_accuracy:  0.97\n",
      "Epoch 8:  train_loss:  0.07,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 9:  train_loss:  0.06,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 10:  train_loss:  0.05,    train_accuracy:  0.98,    valid_loss:  0.13,    valid_accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "# Create a training, validatign loops:\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Create train & valid losses & accuracies:\n",
    "    train_loss = list()\n",
    "    valid_loss = list()\n",
    "    train_accuracy = list()\n",
    "    valid_accuracy = list()\n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in train_ds:\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda() # move x upto cuda so all steps calcuation related to x will be on cuda.\n",
    "        f = model(x)\n",
    "        l = loss(f, y.cuda())\n",
    "        model.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        # Append to loss and accuracies:\n",
    "        train_loss.append(l.item())\n",
    "        train_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in valid_ds:\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda()\n",
    "        with torch.no_grad(): f = model(x)\n",
    "        l = loss(f, y.cuda())\n",
    "        # Append to loss and accuracies:\n",
    "        valid_loss.append(l.item())\n",
    "        valid_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "        \n",
    "    # After done with epoch, print loss of valid and train:\n",
    "    print(f'Epoch {epoch + 1}:  train_loss: {torch.tensor(train_loss).mean(): .2f},\\\n",
    "    train_accuracy: {torch.tensor(train_accuracy).mean(): .2f},\\\n",
    "    valid_loss: {torch.tensor(valid_loss).mean(): .2f},\\\n",
    "    valid_accuracy: {torch.tensor(valid_accuracy).mean(): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46950f39-1f2c-46d9-b5ee-ee8184ecefd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn_model(\n",
       "  (l1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (l2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (l3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (do): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model with nn.Module:\n",
    "class nn_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28*28, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = nn.functional.relu(self.l1(x))\n",
    "        h2 = nn.functional.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "\n",
    "model = nn_model()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "63fc80fd-3d1c-4c6f-b4c0-34ca3963f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss and optimizer:\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc1ccbab-ea0a-47e5-9a83-6ecdc1f7fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  train_loss:  0.42,    train_accuracy:  0.88,    valid_loss:  0.23,    valid_accuracy:  0.93\n",
      "Epoch 2:  train_loss:  0.19,    train_accuracy:  0.94,    valid_loss:  0.17,    valid_accuracy:  0.95\n",
      "Epoch 3:  train_loss:  0.14,    train_accuracy:  0.96,    valid_loss:  0.13,    valid_accuracy:  0.96\n",
      "Epoch 4:  train_loss:  0.11,    train_accuracy:  0.97,    valid_loss:  0.13,    valid_accuracy:  0.96\n",
      "Epoch 5:  train_loss:  0.09,    train_accuracy:  0.97,    valid_loss:  0.12,    valid_accuracy:  0.96\n",
      "Epoch 6:  train_loss:  0.08,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.96\n",
      "Epoch 7:  train_loss:  0.07,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 8:  train_loss:  0.06,    train_accuracy:  0.98,    valid_loss:  0.11,    valid_accuracy:  0.97\n",
      "Epoch 9:  train_loss:  0.05,    train_accuracy:  0.98,    valid_loss:  0.12,    valid_accuracy:  0.97\n",
      "Epoch 10:  train_loss:  0.05,    train_accuracy:  0.99,    valid_loss:  0.12,    valid_accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "# Create a training, validatign loops:\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Create train & valid losses & accuracies:\n",
    "    train_loss = list()\n",
    "    valid_loss = list()\n",
    "    train_accuracy = list()\n",
    "    valid_accuracy = list()\n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in train_ds:\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda() # move x upto cuda so all steps calcuation related to x will be on cuda.\n",
    "        f = model(x)\n",
    "        l = loss(f, y.cuda())\n",
    "        model.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        # Append to loss and accuracies:\n",
    "        train_loss.append(l.item())\n",
    "        train_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "    # loop through every batch of train_ds:\n",
    "    for batch in valid_ds:\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1).cuda()\n",
    "        with torch.no_grad(): f = model(x)\n",
    "        l = loss(f, y.cuda())\n",
    "        # Append to loss and accuracies:\n",
    "        valid_loss.append(l.item())\n",
    "        valid_accuracy.append(y.eq(f.detach().argmax(dim=1).cpu()).float().mean())\n",
    "        \n",
    "    # After done with epoch, print loss of valid and train:\n",
    "    print(f'Epoch {epoch + 1}:  train_loss: {torch.tensor(train_loss).mean(): .2f},\\\n",
    "    train_accuracy: {torch.tensor(train_accuracy).mean(): .2f},\\\n",
    "    valid_loss: {torch.tensor(valid_loss).mean(): .2f},\\\n",
    "    valid_accuracy: {torch.tensor(valid_accuracy).mean(): .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf54cdb-face-42b9-94fb-2dee73cf7223",
   "metadata": {},
   "source": [
    "## Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60129d8-3c3e-41ce-866d-5587d68fa59f",
   "metadata": {},
   "source": [
    "For pytorch-lightning, we need to define:\n",
    "1. Model - similar to pytorch\n",
    "2. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ed8f092a-3e1b-4081-a06d-ce3b98f77f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3ff27f40-3912-4ab6-829b-2a0cdd152248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model:\n",
    "class ImageClassifie(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.do = nn.Dropout(.5)\n",
    "        \n",
    "        # adding loss:\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = nn.functional.relu(self.l1(x))\n",
    "        h2 = nn.functional.relu(self.l2(h1))\n",
    "        do = self.do(h2 + h1)\n",
    "        logits = self.l3(do)\n",
    "        return logits\n",
    "    \n",
    "    # added method:\n",
    "    def configure_optimizers(self):\n",
    "        optimizer= optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    # adđe method:\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        f = self(x)\n",
    "        l = self.loss(f, y)\n",
    "        acc = accuracy(f, y)\n",
    "        bpar = {'train_acc': acc}\n",
    "        # return l   \n",
    "        return {'Loss': l, 'progress_bar': pbar}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        results = self.training_step(batch, batch_idx)\n",
    "        results['progress_bar']['val_acc'] = results['progress_bar']['train_acc']\n",
    "        del results['progress_bar']['train_acc']\n",
    "        return results\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        avg_val_loss = torch.tensor([x['Loss'] for x in val_step_outputs]).mean()\n",
    "        avg_val_acc = torch.tensor([x['progress_bar']['val_acc'] for ax in val_step_outputs]).mean()\n",
    "        pbar = {'val_acc': avg_val_acc}\n",
    "        return {'val_loss': avg_val_loss, 'progress_bar': pbar}\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "    \n",
    "    def setup(self):\n",
    "        dataset = datasets.MNIST('../data', train=False, download=True, transform=transforms.ToTensor())\n",
    "        # Split train, valid randomly:\n",
    "        self.train_ds, self.valid_ds = random_split(mnist_ds, lengths=[55000, 5000])\n",
    "    \n",
    "    # added method:\n",
    "    def train_dataloader(self):\n",
    "\n",
    "        # Create dataloader with batch_size:\n",
    "        batch_size = 64\n",
    "        train_ds = DataLoader(self.train_ds, batch_size)\n",
    "        return train_ds\n",
    "    \n",
    "    def valid_dataloader(self):\n",
    "        batch_size = 64\n",
    "        valid_ds = DataLoader(self.valid_ds, batch_size)\n",
    "        return train_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d78fcfcc-5b2c-4978-a265-2a8f37210c37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (l1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (l2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (l3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (do): Dropout(p=0.5, inplace=False)\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImageClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4e79f7b0-fcb5-4cc9-9fb5-97f1c414a500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type             | Params\n",
      "------------------------------------------\n",
      "0 | l1   | Linear           | 50.2 K\n",
      "1 | l2   | Linear           | 4.2 K \n",
      "2 | l3   | Linear           | 650   \n",
      "3 | do   | Dropout          | 0     \n",
      "4 | loss | CrossEntropyLoss | 0     \n",
      "------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcdaeb6c2c140f0a2d8cb146e339ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(progress_bar_refresh_rate=20, max_epochs=5, gpus=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9bf33e-8031-40f4-99da-097197499a7e",
   "metadata": {},
   "source": [
    "# W&B tag along\n",
    "> Now we're going to add some wandb code into this so that we can see the results of our work as well. Let's say we'll split into pytorch implementation and pytorch lightning implementation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a12e11-492d-4b6d-9e0c-e0307bf3b8a2",
   "metadata": {},
   "source": [
    "## W&B with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "162b6d48-d815-4a9d-a69e-64aa86209835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#State our device:\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d57cb086-fc10-475a-b579-1609f4560785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import W&B and login\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d405c24d-adad-400c-9383-aadfb65b62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME='torch_experiments_mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e17c8599-f9a1-4f0d-adfa-c37856b15d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config:\n",
    "config = dict(\n",
    "    epochs=5,\n",
    "    classes=10,\n",
    "    kernels=[16, 32],\n",
    "    batch_size=128,\n",
    "    learning_rate=3e-4,\n",
    "    dataset='MNIST',\n",
    "    architecture='CNN'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c08f3f-e2a1-4c3c-9f97-4c7e955ef942",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22fa569-0ef3-4c3d-9d2b-7e6b794a6ed4",
   "metadata": {},
   "source": [
    "Next we want to create a pipeline for model:\n",
    "1. Create model\n",
    "2. Train model\n",
    "3. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "69e4cade-58bb-4b80-b447-c2f730b590d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    # tell wandb to start:\n",
    "    with wandb.init(project=PROJECT_NAME, config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches excutions\n",
    "        config = wandb.config\n",
    "        \n",
    "        # make model, train_loader, test_loader, loss, optimizer:\n",
    "        print('Make configurations:')\n",
    "        model, train_loader, test_loader, loss, optimizer = make(config)\n",
    "        print(model)\n",
    "        \n",
    "        # train model:\n",
    "        print('Train model:')\n",
    "        train(model, train_loader, loss, optimizer, config)\n",
    "        \n",
    "        # test model:\n",
    "        print('Test model:')\n",
    "        test(model, test_loader)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ef7e-bc3e-435d-9f11-720d1e3a5bb5",
   "metadata": {},
   "source": [
    "### Make configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "61dfa0e9-42ff-4ad7-a0f7-b0728956cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create make(config):\n",
    "def make(config):\n",
    "    # make data:\n",
    "    print('--Create train, test loaders:')\n",
    "    train, test = get_data(train=True), get_data(train=False) # Here we need to defind get_data\n",
    "    train_loader = create_dataloader(train, batch_size=config.batch_size)\n",
    "    test_loader = create_dataloader(test, batch_size=config.batch_size)\n",
    "    \n",
    "    # make model:\n",
    "    print('--Create model:')\n",
    "    model = ConvNet(config.kernels, config.classes).to(device)\n",
    "    \n",
    "    # make loss and optimizer:\n",
    "    print('--Create loss and optimizer)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    return model, train_loader, test_loader, loss, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a918d1c-93d8-47f0-9c3d-ffb6ca47adab",
   "metadata": {},
   "source": [
    "### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ead8e1de-d490-4d82-99fd-5daa17f95e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader:\n",
    "def get_data(slice=5, train=True):\n",
    "    dataset = datasets.MNIST('./data', train=train, transform=transforms.ToTensor(), download=True)\n",
    "    # Using subset to get data:\n",
    "    sub_dataset = torch.utils.data.Subset(dataset, indices=range(0, len(dataset), slice))\n",
    "    return sub_dataset\n",
    "    \n",
    "def create_dataloader(dataset, batch_size):\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True, pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af51c5e-92d4-44e0-982a-ec9dab5eccb8",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "a727a83f-15b5-4316-b3ff-27c5d8020f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple Convolutional Net:\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, kernels, classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2), # after this, size = (28 + 2 * 2 -5)/1 + 1 = 28 (size + 2* pad - kernel)/stride + 1, 16 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # after this, size = (28-2)/2 + 1 = 14, channels = kernels[0] (kernels[0]x14x14)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2), # new size = 14, channels = kernels[1] (kenels[1]x14x14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # new size = (14-2)/2 + 1 = 7, channels = kernels[1], (kenels[1]x7x7)\n",
    "        )\n",
    "        self.fc = nn.Linear(7 * 7 * kernels[1], classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33065fe1-978c-4126-bc34-90e49560d351",
   "metadata": {},
   "source": [
    "### Create train loop\n",
    "> In this training loop, we want to capture gradients with `wandb.watch()` whilst other hyperparameters with `wandb.log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5013ce04-ba5f-4398-8f85-ceda9b2eedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train loop:\n",
    "def train(model, data_loader, loss, optimizer, config):\n",
    "    # tell wandb to log gradients, weights & others:\n",
    "    print('--Init wandb watch:')\n",
    "    wandb.watch(model, loss, log='all', log_freq=10)\n",
    "    \n",
    "    # run training steps and ask wandb to log things:\n",
    "    print('--loop through epochs:')\n",
    "    total_baches = len(data_loader) * config.epochs\n",
    "    example_ct = 0\n",
    "    batch_ct = 0\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _, (images, labels) in enumerate(data_loader):\n",
    "            batch_loss = train_batch(images, labels, model, optimizer, loss)\n",
    "            example_ct += 1\n",
    "            batch_ct += 1\n",
    "            \n",
    "            # report metrics for every 25 batchs:\n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(batch_loss, example_ct, epoch)\n",
    "        \n",
    "# Define batch training:\n",
    "def train_batch(images, labels, model, optimizer, loss):\n",
    "    # place x & y to device we want to:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # forward pass:\n",
    "    f = model(images)\n",
    "    batch_loss = loss(f, labels)\n",
    "    \n",
    "    # backward pass:\n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    \n",
    "    # update weights with gradients (step):\n",
    "    optimizer.step()    \n",
    "    return batch_loss\n",
    "    \n",
    "\n",
    "# Define what to log during training:\n",
    "def train_log(batch_loss, example_ct, epoch):\n",
    "    batch_loss = float(batch_loss)\n",
    "    \n",
    "    # call wandb to log things:\n",
    "    wandb.log({'epoch': epoch, 'loss': batch_loss}, step=example_ct)\n",
    "    print(f'Loss after:' + str(example_ct).zfill(5) + f' examples: {batch_loss: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771671c-8575-4053-bbe0-daf52610e4e7",
   "metadata": {},
   "source": [
    "### Create test loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0d91cf0e-9dcb-42b2-8876-cf5354df1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            f = model(images)\n",
    "            _, labels_hat = torch.max(f.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (labels_hat == labels).sum().item()\n",
    "\n",
    "        print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test images: {100 * correct / total}%\")\n",
    "        \n",
    "        wandb.log({\"test_accuracy\": correct / total})\n",
    "\n",
    "    # Save the model in the exchangeable ONNX format\n",
    "    torch.onnx.export(model, images, \"model.onnx\")\n",
    "    wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "965fe53c-a962-4da2-b12b-8807ed940f89",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "90040203-8de6-4804-92a3-a39b405caf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">hearty-smoke-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist/runs/1j4x59eo\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist/runs/1j4x59eo</a><br/>\n",
       "                Run data is saved locally in <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210928_054947-1j4x59eo</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "--Init wandb watch:\n",
      "--loop through epochs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f400cccaab41d8a8ae8dd9e4a629c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after:00024 examples:  2.077\n",
      "Loss after:00049 examples:  1.384\n",
      "Loss after:00074 examples:  0.709\n",
      "Loss after:00099 examples:  0.554\n",
      "Loss after:00124 examples:  0.391\n",
      "Loss after:00149 examples:  0.366\n",
      "Loss after:00174 examples:  0.351\n",
      "Loss after:00199 examples:  0.299\n",
      "Loss after:00224 examples:  0.280\n",
      "Loss after:00249 examples:  0.217\n",
      "Loss after:00274 examples:  0.186\n",
      "Loss after:00299 examples:  0.247\n",
      "Loss after:00324 examples:  0.192\n",
      "Loss after:00349 examples:  0.256\n",
      "Loss after:00374 examples:  0.221\n",
      "Loss after:00399 examples:  0.216\n",
      "Loss after:00424 examples:  0.185\n",
      "Loss after:00449 examples:  0.107\n",
      "Accuracy of the model on the 2000 test images: 93.95%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14486<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.11MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210928_054947-1j4x59eo/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210928_054947-1j4x59eo/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>22</td></tr><tr><td>_timestamp</td><td>1632783009</td></tr><tr><td>_step</td><td>449</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.10737</td></tr><tr><td>test_accuracy</td><td>0.9395</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▃▃▃▃▅▅▅▅▆▆▆▆███</td></tr><tr><td>loss</td><td>█▆▃▃▂▂▂▂▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">hearty-smoke-6</strong>: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist/runs/1j4x59eo\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist/runs/1j4x59eo</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run every thing:\n",
    "model = model_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3aac29b7-d945-46f2-8fbf-2d1e30b89247",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e640c02-d6da-4dbf-802c-2bc033c57c0d",
   "metadata": {},
   "source": [
    "## W&B with pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d7c982-29a2-4156-8e19-ddb3e7136952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 497020700\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "pl.seed_everything(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c903809a-1c71-41a3-a6bf-21d44410dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to redo what we did before with pytorhc-lightning:\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, in_dims, n_classes=10, n_layer1=128, n_layer2=256, lr=3e-4):\n",
    "        super().__init__()\n",
    "        # Create layers:\n",
    "        self.l1 = nn.Linear(np.prod(in_dims), n_layer1)\n",
    "        self.l2 = nn.Linear(n_layer1, n_layer2)\n",
    "        self.l3 = nn.Linear(n_layer2, n_classes)\n",
    "        \n",
    "        # log parameters:\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Compute accuracy:\n",
    "        self.train_acc = pl.metrics.Accuracy()\n",
    "        self.valid_acc = pl.metrics.Accuracy()\n",
    "        self.test_acc = pl.metrics.Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, *dims = x.size()\n",
    "        \n",
    "        # Stem:\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # Learner:\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        \n",
    "        # task: compute logits:\n",
    "        x = F.log_softmax(self.l3(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # Method to get loss:\n",
    "    def loss(self, xs, ys):\n",
    "        logits = self(xs) # call forward\n",
    "        loss = F.nll_loss(logits, ys)\n",
    "        return logits, loss\n",
    "    \n",
    "    # Add method: trainning_step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, ys = batch\n",
    "        logits, loss = self.loss(xs, ys)\n",
    "        preds =  torch.argmax(logits, 1)\n",
    "        \n",
    "        # Logging metrics we calculate\n",
    "        self.log('train/loss', loss, on_epoch=True)\n",
    "        \n",
    "        # Logging pl.Metric:\n",
    "        self.train_acc(preds, ys)\n",
    "        self.log('train/acc', self.train_acc, on_epoch=True)\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b7b0b-3d08-47c9-89e1-02ca3a4849ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optinal method for logging\n",
    "> We need to create callbacks from this:\n",
    "- Methods that trigger each batch for a dataset: `validation_step` and `test_step`\n",
    "- Methods that trigger at the end of an epoch: `{training|validation|test}_epoch_end`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f1ff6-90f3-4d42-9db9-c1662da9737d",
   "metadata": {},
   "source": [
    "**Test step:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee57ad4-953b-4c5c-b70f-e77f2eaf8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(self, batch, batch_idx):\n",
    "    xs, ys = batch\n",
    "    logits, loss = self.loss(xs, ys)\n",
    "    preds = torch.argmax(logits, 1)\n",
    "    self.log('test/loss_epoch', loss, on_step=False, on_epoch=True)\n",
    "    self.log('test/acc_epoch', self.test_acc, on_step=False, on_epoch=True)\n",
    "    \n",
    "# Update to ImageClassifier:\n",
    "ImageClassifier.test_step = test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0b341b-77a3-48c7-bef1-40b2bac7633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model:\n",
    "def test_epoch_end(self, test_step_outputs):\n",
    "    dummy_input = torch.zeros(self.hparams['in_dims'], device=self.device)\n",
    "    model_filename = 'model_final.onnx'\n",
    "    torch.onnx.export(self, dummy_input, model_filename, opset_version=11)\n",
    "    \n",
    "ImageClassifier.test_epoch_end = test_epoch_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975622d0-b86f-442f-b888-33eecd4812ef",
   "metadata": {},
   "source": [
    "**Validation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc674ba-8de3-48e4-8514-560add3f068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    xs, ys = batch\n",
    "    logits, loss = self.loss(xs, ys)\n",
    "    preds = torch.argmax(logits, 1)\n",
    "    self.valid_acc(preds, ys)\n",
    "    \n",
    "    # log:\n",
    "    self.log('validation/loss_epoch', loss)\n",
    "    self.log('validation/acc_epoch', self.valid_acc)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def validation_epoch_end(self, validation_epoch_outputs):\n",
    "    dump_input = torch.zeros(self.hparams['in_dims'], device=self.device)\n",
    "    model_filename = f'model_{str(self.global_step).zfill(5)}.onnx'\n",
    "    torch.onnx.export(self, dummy_input, model_filename, opset_version=11)\n",
    "    wandb.save(model_filename)\n",
    "    \n",
    "    flattend_logits = torch.flatten(torch.cat(validation_epoch_outputs))\n",
    "    self.logger.experiment.log(\n",
    "        {'valid/logits': wandb.Histogram(flattend_logits.to('cpu')),\n",
    "         'global_step': self.global_step}\n",
    "    )\n",
    "    \n",
    "ImageClassifier.validation_step = validation_step\n",
    "ImageClassifier.valid_epoch_end = validation_epoch_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc6f61-2737-4332-8402-5822cdc771f0",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75875c52-4342-4a60-a53b-11a392805ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback to log further things:\n",
    "class ImagePredictionLogger(pl.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.val_images, self.val_labels = val_samples\n",
    "        self.val_images = self.val_images[:num_samples]\n",
    "        self.val_labels = self.val_labels[:num_samples]\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_images = self.val_images.to(device=pl_module.device)\n",
    "        \n",
    "        logits = pl_module(val_images)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        \n",
    "        trainer.logger.experiment.log(\n",
    "            {'examples': [wandb.Image(x, caption=f'Pred:{pred}, Labels{y}')\n",
    "                         for x, pred, y in zip(val_images, val_labels, preds)],\n",
    "             'global_step': trainer.global_step}\n",
    "        )       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd33a57-d1a4-400f-9342-5f240411be16",
   "metadata": {},
   "source": [
    "### Load data:\n",
    "> We can load data using:\n",
    "- pytorch `DataLoaders`\n",
    "- pytorch-lightning `DataModules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf3110b-ec1a-47b9-a3bf-85aca31da137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataModules(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir='./data', batch_size=128):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist, [55000, 5000])\n",
    "        if stage == 'test' or stage is None:\n",
    "            mnist = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "    # separate data loader for train, valid, test:\n",
    "    def train_dataloader(self):\n",
    "        mnist_train = DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "        return mnist_train\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        mnist_val = DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "        return mnist_val\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        mnist_test = DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "        return mnist_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d49844-f2fb-40f0-8ac4-6dbfbe754d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data:\n",
    "mnist = ImageDataModules()\n",
    "mnist.prepare_data()\n",
    "mnist.setup()\n",
    "\n",
    "samples = next(iter(mnist.val_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad6fce-f3b2-4441-9fbb-ada0596f687a",
   "metadata": {},
   "source": [
    "### Making trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "762f8ae9-2526-458b-9a2e-42cc25ca0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create wandb loger:\n",
    "PROJECT_NAME = 'torch_experiments_mnist'\n",
    "wandb_logger = WandbLogger(project=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0e9d00e-1c9a-495c-b592-bab8adb99e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger = wandb_logger,\n",
    "    log_every_n_steps=50,\n",
    "    gpus=1, \n",
    "    max_epochs=10,\n",
    "    deterministic=True,\n",
    "    callbacks=[ImagePredictionLogger(samples)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166662a9-e33c-47be-8106-473972f51474",
   "metadata": {},
   "source": [
    "### Runing the whole thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33900b30-29b3-413a-a6d0-dc0762758b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fancy-sky-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist/runs/e1zy83dy\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist/runs/e1zy83dy</a><br/>\n",
       "                Run data is saved locally in <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210929_105944-e1zy83dy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | l1        | Linear   | 100 K \n",
      "1 | l2        | Linear   | 33.0 K\n",
      "2 | l3        | Linear   | 2.6 K \n",
      "3 | train_acc | Accuracy | 0     \n",
      "4 | valid_acc | Accuracy | 0     \n",
      "5 | test_acc  | Accuracy | 0     \n",
      "---------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da267f1f0a024624922cc5a2a659fa66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddpham/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 267<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210929_105944-e1zy83dy/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ddpham/git/intro-pytorch-lightning/nbs/wandb/run-20210929_105944-e1zy83dy/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>9</td></tr><tr><td>train/acc_epoch</td><td>0.98993</td></tr><tr><td>train/acc_step</td><td>1.0</td></tr><tr><td>train/loss_epoch</td><td>0.03786</td></tr><tr><td>train/loss_step</td><td>0.01854</td></tr><tr><td>trainer/global_step</td><td>4299</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/acc_epoch</td><td>▁▅▆▇▇▇████</td></tr><tr><td>train/acc_step</td><td>▁▄▄▄▅▇▅▇▇▆▇▇▇▇▆▇█▇▇▇▇▇▇██▇▇▇█▇▇██▇█▇▇█▇▇</td></tr><tr><td>train/loss_epoch</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>train/loss_step</td><td>█▅▅▄▃▂▄▂▂▂▂▃▂▂▃▂▁▂▂▂▁▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fancy-sky-8</strong>: <a href=\"https://wandb.ai/ddpham/torch_experiments_mnist/runs/e1zy83dy\" target=\"_blank\">https://wandb.ai/ddpham/torch_experiments_mnist/runs/e1zy83dy</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ImageClassifier(in_dims=(1, 28, 28))\n",
    "trainer.fit(model, mnist)\n",
    "trainer.test(datamodule=mnist, ckpt_path=None)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f93fb3-9b0b-4428-80e7-bb92716f9c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
